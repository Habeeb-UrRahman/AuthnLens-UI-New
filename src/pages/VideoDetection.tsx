
import { useState } from 'react';
import Layout from '@/components/Layout';
import FileUpload from '@/components/FileUpload';
import DetectionResult from '@/components/DetectionResult';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { useToast } from '@/components/ui/use-toast';

const VideoDetection = () => {
  const [file, setFile] = useState<File | null>(null);
  const [videoPreview, setVideoPreview] = useState<string | null>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [analysisComplete, setAnalysisComplete] = useState(false);
  const [analysisResult, setAnalysisResult] = useState<{ isAI: boolean; confidence: number } | undefined>();
  const { toast } = useToast();

  const handleFileSelected = (selectedFile: File) => {
    setFile(selectedFile);
    setAnalysisComplete(false);
    setAnalysisResult(undefined);
    
    // Create video preview
    const url = URL.createObjectURL(selectedFile);
    setVideoPreview(url);
  };

  const handleAnalyzeClick = () => {
    if (!file) {
      toast({
        title: "No video selected",
        description: "Please upload a video to analyze",
        variant: "destructive",
      });
      return;
    }

    setIsAnalyzing(true);
    setAnalysisComplete(false);
    
    // Simulate API call to ML model
    setTimeout(() => {
      // This is where you would actually call your Keras model API
      const mockResult = {
        isAI: Math.random() > 0.5, // Random result for now
        confidence: 0.7 + Math.random() * 0.25, // Random confidence between 70-95%
      };
      
      setAnalysisResult(mockResult);
      setIsAnalyzing(false);
      setAnalysisComplete(true);
      
      toast({
        title: "Analysis complete",
        description: mockResult.isAI 
          ? "This video appears to be AI-generated" 
          : "This video appears to be human-created",
      });
    }, 5000); // Longer time since video analysis is typically more complex
  };

  const handleReset = () => {
    if (videoPreview) {
      URL.revokeObjectURL(videoPreview);
    }
    setFile(null);
    setVideoPreview(null);
    setIsAnalyzing(false);
    setAnalysisComplete(false);
    setAnalysisResult(undefined);
  };

  return (
    <Layout>
      <div className="container mx-auto px-4 py-10">
        <div className="max-w-4xl mx-auto">
          <div className="text-center mb-10">
            <h1 className="text-3xl md:text-4xl font-bold mb-4">Video Detection</h1>
            <p className="text-muted-foreground">
              Upload a video to determine whether it was generated by AI or created by a human
            </p>
          </div>
          
          <div className="grid md:grid-cols-5 gap-8">
            <div className="md:col-span-3 space-y-6">
              {/* Uploader Section */}
              <Card>
                <CardContent className="p-6">
                  <FileUpload
                    accept="video/mp4,video/webm,video/quicktime"
                    maxSize={20}
                    onFileSelected={handleFileSelected}
                  />
                  
                  <div className="flex justify-center mt-6 space-x-4">
                    <Button 
                      onClick={handleAnalyzeClick} 
                      disabled={!file || isAnalyzing}
                      className="w-full md:w-auto"
                    >
                      {isAnalyzing ? "Analyzing..." : "Analyze Video"}
                    </Button>
                    
                    {(file || analysisComplete) && (
                      <Button 
                        variant="outline" 
                        onClick={handleReset}
                        className="w-full md:w-auto"
                      >
                        Reset
                      </Button>
                    )}
                  </div>
                </CardContent>
              </Card>
              
              {/* Video Preview */}
              {videoPreview && (
                <Card className="overflow-hidden animate-fade-in">
                  <div className="aspect-video bg-muted/50 flex items-center justify-center">
                    <video 
                      src={videoPreview} 
                      controls 
                      className="max-w-full max-h-full"
                    />
                  </div>
                </Card>
              )}
            </div>
            
            <div className="md:col-span-2">
              <DetectionResult
                loading={isAnalyzing}
                completed={analysisComplete}
                result={analysisResult}
              />
              
              {analysisComplete && analysisResult && (
                <div className="mt-6 p-4 rounded-lg bg-muted animate-fade-in">
                  <h3 className="font-medium mb-2">Detection Details:</h3>
                  <ul className="space-y-2 text-sm">
                    <li><strong>Analysis Method:</strong> Frame-by-Frame Neural Analysis</li>
                    <li><strong>Model:</strong> AuraVision Video v1.0</li>
                    <li><strong>Frames Analyzed:</strong> Sample Rate: 1fps</li>
                    <li className="text-muted-foreground pt-2 text-xs">
                      Note: This is a demonstration. In the real application, your Keras model would provide the actual detection results.
                    </li>
                  </ul>
                </div>
              )}
            </div>
          </div>
        </div>
      </div>
    </Layout>
  );
};

export default VideoDetection;
