
import { useState } from 'react';
import Layout from '@/components/Layout';
import FileUpload from '@/components/FileUpload';
import DetectionResult from '@/components/DetectionResult';
import { Card, CardContent } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { useToast } from '@/components/ui/use-toast';

const AudioDetection = () => {
  const [file, setFile] = useState<File | null>(null);
  const [audioPreview, setAudioPreview] = useState<string | null>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [analysisComplete, setAnalysisComplete] = useState(false);
  const [analysisResult, setAnalysisResult] = useState<{ isAI: boolean; confidence: number } | undefined>();
  const { toast } = useToast();

  const handleFileSelected = (selectedFile: File) => {
    setFile(selectedFile);
    setAnalysisComplete(false);
    setAnalysisResult(undefined);
    
    // Create audio preview
    const url = URL.createObjectURL(selectedFile);
    setAudioPreview(url);
  };

  const handleAnalyzeClick = () => {
    if (!file) {
      toast({
        title: "No audio selected",
        description: "Please upload an audio file to analyze",
        variant: "destructive",
      });
      return;
    }

    setIsAnalyzing(true);
    setAnalysisComplete(false);
    
    // Simulate API call to ML model
    setTimeout(() => {
      // This is where you would actually call your Keras model API
      const mockResult = {
        isAI: Math.random() > 0.5, // Random result for now
        confidence: 0.7 + Math.random() * 0.25, // Random confidence between 70-95%
      };
      
      setAnalysisResult(mockResult);
      setIsAnalyzing(false);
      setAnalysisComplete(true);
      
      toast({
        title: "Analysis complete",
        description: mockResult.isAI 
          ? "This audio appears to be AI-generated" 
          : "This audio appears to be human-created",
      });
    }, 4000);
  };

  const handleReset = () => {
    if (audioPreview) {
      URL.revokeObjectURL(audioPreview);
    }
    setFile(null);
    setAudioPreview(null);
    setIsAnalyzing(false);
    setAnalysisComplete(false);
    setAnalysisResult(undefined);
  };

  return (
    <Layout>
      <div className="container mx-auto px-4 py-10">
        <div className="max-w-4xl mx-auto">
          <div className="text-center mb-10">
            <h1 className="text-3xl md:text-4xl font-bold mb-4">Audio Detection</h1>
            <p className="text-muted-foreground">
              Upload an audio file to determine whether it was generated by AI or created by a human
            </p>
          </div>
          
          <div className="grid md:grid-cols-5 gap-8">
            <div className="md:col-span-3 space-y-6">
              {/* Uploader Section */}
              <Card>
                <CardContent className="p-6">
                  <FileUpload
                    accept="audio/*"
                    maxSize={10}
                    onFileSelected={handleFileSelected}
                  />
                  
                  <div className="flex justify-center mt-6 space-x-4">
                    <Button 
                      onClick={handleAnalyzeClick} 
                      disabled={!file || isAnalyzing}
                      className="w-full md:w-auto"
                    >
                      {isAnalyzing ? "Analyzing..." : "Analyze Audio"}
                    </Button>
                    
                    {(file || analysisComplete) && (
                      <Button 
                        variant="outline" 
                        onClick={handleReset}
                        className="w-full md:w-auto"
                      >
                        Reset
                      </Button>
                    )}
                  </div>
                </CardContent>
              </Card>
              
              {/* Audio Preview */}
              {audioPreview && (
                <Card className="overflow-hidden animate-fade-in">
                  <CardContent className="p-6">
                    <div className="w-full bg-muted/50 p-4 rounded-lg">
                      <audio 
                        src={audioPreview} 
                        controls 
                        className="w-full"
                      />
                    </div>
                    <div className="mt-4 text-sm text-muted-foreground text-center">
                      Listen to the audio to check if you can hear any artificial patterns or artifacts
                    </div>
                  </CardContent>
                </Card>
              )}
            </div>
            
            <div className="md:col-span-2">
              <DetectionResult
                loading={isAnalyzing}
                completed={analysisComplete}
                result={analysisResult}
              />
              
              {analysisComplete && analysisResult && (
                <div className="mt-6 p-4 rounded-lg bg-muted animate-fade-in">
                  <h3 className="font-medium mb-2">Detection Details:</h3>
                  <ul className="space-y-2 text-sm">
                    <li><strong>Analysis Method:</strong> Spectrogram Analysis</li>
                    <li><strong>Model:</strong> AuraSound v1.0</li>
                    <li><strong>Audio Length:</strong> {file?.size ? `${(file.size / (1024 * 1024)).toFixed(2)} MB` : 'Unknown'}</li>
                    <li className="text-muted-foreground pt-2 text-xs">
                      Note: This is a demonstration. In the real application, your Keras model would provide the actual detection results.
                    </li>
                  </ul>
                </div>
              )}
            </div>
          </div>
        </div>
      </div>
    </Layout>
  );
};

export default AudioDetection;
